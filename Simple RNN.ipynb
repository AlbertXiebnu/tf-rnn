{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -tf\n",
    "%aimport data\n",
    "%aimport model\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data\n",
    "import model\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "MAX_DOCUMENT_LENGTH = 20\n",
    "VOCAB_MIN_FREQUENCY = 50\n",
    "DATA_TEST_SIZE = 5000\n",
    "\n",
    "# Model Parameters\n",
    "RNN_CELL_SIZE = 128\n",
    "EMBEDDING_DIM = 128\n",
    "\n",
    "# Training Parameters\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "TRAIN_EVAL_EVERY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = data.load_reddit_data(\n",
    "    max_document_length=MAX_DOCUMENT_LENGTH,\n",
    "    min_frequency=VOCAB_MIN_FREQUENCY,\n",
    "    test_size=DATA_TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 10803\n",
      "Train Data Shape: (385367, 20)\n",
      "Dev Data Shape (5000, 20)\n",
      "Vocabulary size 10803\n"
     ]
    }
   ],
   "source": [
    "data.print_dataset_stats(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_input_fn, dev_input_fn = data.create_train_dev_input_fns(ds, batch_size=TRAIN_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_rnn(sequences, sequence_lengths):\n",
    "    cell = tf.nn.rnn_cell.GRUCell(RNN_CELL_SIZE)\n",
    "    sequence_list = tf.unpack(sequences, axis=1)\n",
    "    return tf.nn.rnn(cell, sequence_list, dtype=tf.float32, sequence_length=sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Monitor for sampling sentences from the estimator\n",
    "sample_mon = model.SentenceSampleMonitor(\n",
    "    vocab=ds.vocab,\n",
    "    every_n_steps=TRAIN_EVAL_EVERY,\n",
    "    first_n_steps=-1)\n",
    "\n",
    "# Monitor for development set loss\n",
    "dev_monitor = tf.contrib.learn.monitors.ValidationMonitor(\n",
    "    input_fn=dev_input_fn,\n",
    "    max_sample_length=10,\n",
    "    num_samples=5,\n",
    "    every_n_steps=TRAIN_EVAL_EVERY)\n",
    "\n",
    "# The function to create the model\n",
    "model_fn = model.create_language_model_rnn(\n",
    "    vocab_size=len(ds.vocab.vocabulary_),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_fn=simple_rnn)\n",
    "\n",
    "model_name = \"maxlen_{}_rnn{}_embed_{}\".format(MAX_DOCUMENT_LENGTH, RNN_CELL_SIZE, EMBEDDING_DIM)\n",
    "estimator = tf.contrib.learn.Estimator(model_fn=model_fn, model_dir=\"./checkpoints/{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Setting feature info to {'x_len': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(8)]), is_sparse=False), 'x': TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(8), Dimension(20)]), is_sparse=False)}\n",
      "WARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(8), Dimension(19)]), is_sparse=False)\n",
      "INFO:tensorflow:Create CheckpointSaver\n",
      "INFO:tensorflow:Restored model from ./checkpoints/maxlen_20_rnn128_embed_128/model.ckpt-1800-?????-of-00001\n"
     ]
    }
   ],
   "source": [
    "estimator.fit(input_fn=train_input_fn, steps=None, monitors=[sample_mon, dev_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
